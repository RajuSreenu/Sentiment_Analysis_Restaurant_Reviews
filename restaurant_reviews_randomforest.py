# -*- coding: utf-8 -*-
"""Restaurant_Reviews_RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mcbhi9ZfFOymsWgC0qmVaWsJehGhwkpZ
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/Restaurant_Reviews.tsv",delimiter='\t',quoting=3)

df.shape,df.columns

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Liked'], test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # max_features
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X_train_tfidf, y_train)

y_pred =model.predict(X_test_tfidf)
y_pred

param_grid = {
	'n_estimators': [25, 50, 100, 150],
	'max_features': ['sqrt', 'log2', None],
	'max_depth': [3, 6, 9],
	'max_leaf_nodes': [3, 6, 9],
}

from sklearn.model_selection import GridSearchCV
grid_search = GridSearchCV(RandomForestClassifier(),param_grid=param_grid)
grid_search.fit(X_train_tfidf, y_train)
print(grid_search.best_estimator_)

from sklearn.metrics import classification_report
model_grid = RandomForestClassifier(max_depth=9,
									max_features="log2",
									max_leaf_nodes=9,
									n_estimators=25)
model_grid.fit(X_train_tfidf, y_train)
y_pred_grid = model.predict(X_test_tfidf)
print(classification_report(y_pred_grid, y_test))

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import classification_report
score1=accuracy_score(y_test,y_pred)
score2=precision_score(y_test,y_pred)
score3=recall_score(y_test,y_pred)
report = classification_report(y_test, y_pred)
print("Accuracy Score is :{}%".format(round(score1*100,2)))
print("Precision Score is :{}%".format(round(score2*100,2)))
print("Recall Score is :{}%".format(round(score3*100,2)))
print("Classification Report:\n", report)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_pred)
cm

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Calculating the confusion matrix
cm = confusion_matrix(y_test, y_pred)

class_names = ['Negative', 'Positive']

# Creating a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size for better readability
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)

# Adding labels and a title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Displaying the plot
plt.show()

from sklearn.manifold import TSNE

# Assuming you have already performed sentiment analysis and have TF-IDF vectors
# X_train_tfidf and X_test_tfidf from the previous example

# Combining the training and test sets for visualization
X_combined = np.vstack((X_train_tfidf.toarray(), X_test_tfidf.toarray()))
y_combined = np.hstack((y_train, y_test))

# Performing t-SNE dimensionality reduction
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_combined)
# Plotting the results
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_combined, cmap='coolwarm')
plt.colorbar(scatter, label='Sentiment (0: Negative, 1: Positive)')
plt.title('t-SNE Visualization of Sentiment Analysis Results RandomForest')
plt.show()

score1=accuracy_score(y_test,y_pred_grid)
score2=precision_score(y_test,y_pred_grid)
score3=recall_score(y_test,y_pred_grid)
cm = confusion_matrix(y_test, y_pred_grid)
# Printing the results
print("Accuracy Score is :{}%".format(round(score1*100,2)))
print("Precision Score is :{}%".format(round(score2*100,2)))
print("Recall Score is :{}%".format(round(score3*100,2)))
cm