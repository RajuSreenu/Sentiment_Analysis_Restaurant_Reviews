# -*- coding: utf-8 -*-
"""Restaurant_Reviews_Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XOsTU3LQkmOGiTxaPE_345glSmIZaLO
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv("/content/drive/MyDrive/Restaurant_Reviews (1).tsv",delimiter='\t',quoting=3)

df.head()

# library to clean data
import re

# Natural Language Tool Kit
import nltk

nltk.download('stopwords')

# to remove stopword
from nltk.corpus import stopwords

# for Stemming propose
from nltk.stem.porter import PorterStemmer

# Initialize empty array
# to append clean text
corpus = []

# 1000 (reviews) rows to clean
for i in range(0, 1000):

	# column : "Review", row ith
	review = re.sub('[^a-zA-Z]', repl=' ',string= df['Review'][i])

	# convert all cases to lower cases
	review = review.lower()

	# split to array(default delimiter is " ")
	review = review.split()

	# creating PorterStemmer object to
	# take main stem of each word
	ps = PorterStemmer()

	# loop for stemming each word
	# in string array at ith row
	review = [ps.stem(word) for word in review
				if not word in set(stopwords.words('english'))]

	# rejoin all string array elements
	# to create back into a string
	review = ' '.join(review)

	# append each string to create
	# array of clean text
	corpus.append(review)

corpus[:1500]

# Creating the Bag of Words model
from sklearn.feature_extraction.text import CountVectorizer

# To extract max 1500 feature.
# "max_features" is attribute to
# experiment with to get better results
cv = CountVectorizer(max_features = 1500)

# X contains corpus (dependent variable)
X = cv.fit_transform(corpus).toarray()

# y contains answers if review
# is positive or negative
y = df.iloc[:, 1].values

# Splitting the dataset into
# the Training set and Test set
from sklearn.model_selection import train_test_split

# experiment with "test_size"
# to get better results
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn import linear_model
classifier = linear_model.LogisticRegression(C=1.5)
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import classification_report
score1=accuracy_score(y_test,y_pred)
score2=precision_score(y_test,y_pred)
score3=recall_score(y_test,y_pred)
report = classification_report(y_test, y_pred)
print("Accuracy Score is :{}%".format(round(score1*100,2)))
print("Precision Score is :{}%".format(round(score2*100,2)))
print("Recall Score is :{}%".format(round(score3*100,2)))
print("Classification Report:\n", report)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_pred)
cm

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Calculating the confusion matrix
cm = confusion_matrix(y_test, y_pred)

class_names = ['Negative', 'Positive']

# Creating a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)  # Adjust font size for better readability
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)

# Adding labels and a title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')

# Displaying the plot
plt.show()

from sklearn.manifold import TSNE

# Assuming you have already performed sentiment analysis and have TF-IDF vectors
# X_train_tfidf and X_test_tfidf from the previous example

# Combining the training and test sets for visualization
X_combined = np.vstack((X_train, X_test))
y_combined = np.hstack((y_train, y_test))

# Performing t-SNE dimensionality reduction
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_combined)
# Plotting the results
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_combined, cmap='coolwarm')
plt.colorbar(scatter, label='Sentiment (0: Negative, 1: Positive)')
plt.title('t-SNE Visualization of Sentiment Analysis Results Logistic Regression')
plt.show()

score1=accuracy_score(y_test,y_pred)
score2=precision_score(y_test,y_pred)
score3=recall_score(y_test,y_pred)
cm = confusion_matrix(y_test, y_pred)
# Printing the results
print("Accuracy Score is :{}%".format(round(score1*100,2)))
print("Precision Score is :{}%".format(round(score2*100,2)))
print("Recall Score is :{}%".format(round(score3*100,2)))
cm